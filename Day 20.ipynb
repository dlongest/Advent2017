{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code Day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import read_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_particles(filename):\n",
    "    \n",
    "    lines = read_input(filename)\n",
    "    \n",
    "    particles = [parse_particle_input(line) for line in lines]\n",
    "    \n",
    "    return particles\n",
    "\n",
    "def parse_particle_input(particle_element):\n",
    "    parts = [p.strip() for p in particle_element.split('>,')]\n",
    "  \n",
    "    position = tuple([int(p) for p in parts[0][3:].split(',')])\n",
    "  \n",
    "    velocity =  tuple([int(p) for p in parts[1][3:].split(',')])\n",
    " \n",
    "    acceleration = tuple([int(p) for p in parts[2][3:-1].split(',')])\n",
    "    \n",
    "    return (position, velocity, acceleration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part One Functions\n",
    "\n",
    "For part one, we really only need 2 functions - one to compute the Manhattan distance from two 3D vectors (as tuples).  The other is to produce a new vector (as tuple) given two vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def manhattan_distance(one, two):\n",
    "    \n",
    "    return abs(one[0] - two[0]) + abs(one[1] - two[1]) + abs(one[2] - two[2])\n",
    "\n",
    "def add_vectors(one, two):\n",
    "    return (one[0] + two[0], one[1] + two[1], one[2] + two[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part One\n",
    "\n",
    "The key to this problem is the acceleration of each particle will never change.  Every particle begins with some position and velocity but both are adjusted by their acceleration each time unit.  It may be the case that some particles will move temporarily towards the origin, but long-term, all will be moving away from the origin.  The question is: which one will be closest?  The one whose acceleration is the slowest.  To determine that, we'll just use Manhattan distance of the acceleration for each particle and the minimum such acceleration is for the particle that will ultimately be closest.  Despite what the problem implies, we never have to simulate anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_part_one():\n",
    "       \n",
    "    origin = (0, 0, 0)\n",
    "\n",
    "    p = read_particles('Input/day20.txt')\n",
    "    \n",
    "    accelerations = [acc for (_, _, acc) in p]\n",
    "\n",
    "    distances = [manhattan_distance(acc, origin) for acc in accelerations]\n",
    "    \n",
    "    print 'Particle {} will always be closest to origin'.format(np.argmin(distances))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solve_part_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "\n",
    "There are a few options to find colliding particles but I'll use a rather bruteforce one and simulate movements of the particles and look for collisions.  There are physics equations to compute position for any unit of time given starting velocity and acceleration, but we'll just make stepwise updates to velocity and position.  First, update_particles takes a collection of tuples (position, velocity, acceleration) and uses update_particle to produce a new collection that has the same acceleration but updated velocity and position.  Then who_survives returns only those particles that survive based on position, using survives to determine if any other particle shares the same position for each particle.  The only real question is: how do we know when all collisions have occurred?  We'll just take a gamble that 1000 time units is sufficient for all collisions to have occurred and that no particles end up on the same path with one trailing the other.  It's possible to determine a stopping point based on having all particles moving away from the origin and none sharing a normalized vector, but we'll just go the easy route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_particle(particle):\n",
    "    \n",
    "    ((x, y, z), (vx, vy, vz), (ax, ay, az)) = particle\n",
    "    \n",
    "    acc = (ax, ay, az)\n",
    "    vel = (vx + ax, vy + ay, vz + az)\n",
    "    pos = (x + vel[0], y + vel[1], z + vel[2])\n",
    "    \n",
    "    return (pos, vel, acc)\n",
    "\n",
    "def update_particles(particles):\n",
    "    \n",
    "    return [update_particle(particle) for particle in particles]\n",
    "\n",
    "\n",
    "def survives(current_index, particles):\n",
    "    \n",
    "    for ix, (pos, vel, acc) in enumerate(particles):\n",
    "        if particles[current_index][0] == pos and ix != current_index:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def who_survives(particles):\n",
    "    \n",
    "    return [particles[ix] for ix in xrange(0, len(particles)) if survives(ix, particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def solve_part_two():\n",
    "        \n",
    "    particles = read_particles('Input/day20.txt')\n",
    "    \n",
    "    for iteration in xrange(1, 1000):\n",
    "        \n",
    "        particles = update_particles(particles)\n",
    "        \n",
    "        particles = who_survives(particles)\n",
    "    \n",
    "    print '{} particles survived'.format(len(particles))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solve_part_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
